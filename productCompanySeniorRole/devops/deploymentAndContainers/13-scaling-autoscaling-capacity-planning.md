Good. Now we move to scaling maturity.

---

# ðŸ“ File: `13-scaling-autoscaling-capacity-planning.md`

# ðŸ”¥ STEP 13 â€” Horizontal Scaling + HPA + Capacity Planning

(Senior Backend Scaling Intelligence)

This is where backend engineers prove they understand **real traffic behavior**.

Interviewers ask:

* How do you scale a microservice?
* What is HPA?
* CPU-based vs memory-based scaling?
* What happens during traffic spike?
* What are scaling pitfalls?

This file gives you full clarity.

---

# ðŸ§  1ï¸âƒ£ Types of Scaling

## ðŸ”¹ Vertical Scaling (Scale Up)

Increase resources of same instance.

Example:

* 2GB â†’ 8GB RAM
* 1 CPU â†’ 4 CPUs

Problems:

âŒ Hardware limit
âŒ Downtime required
âŒ Expensive

Used rarely in cloud-native systems.

---

## ðŸ”¹ Horizontal Scaling (Scale Out)

Increase number of instances.

Example:

* 3 pods â†’ 10 pods

âœ” No downtime
âœ” Cloud-native
âœ” More resilient

This is default strategy in Kubernetes.

---

# ðŸ§  2ï¸âƒ£ Horizontal Pod Autoscaler (HPA)

Kubernetes can auto-scale based on metrics.

Example:

```yaml
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: myapp-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: myapp
  minReplicas: 3
  maxReplicas: 10
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
```

Meaning:

* If CPU > 70% â†’ scale up
* If CPU < threshold â†’ scale down

---

# ðŸ§  3ï¸âƒ£ CPU-Based Scaling

Most common metric.

Why?

CPU correlates with:

* Request load
* Computation effort

But not always enough.

---

# ðŸ§  4ï¸âƒ£ Memory-Based Scaling

Scale when memory usage high.

Example:

```yaml
resource:
  name: memory
  target:
    type: Utilization
    averageUtilization: 75
```

Be careful:

Memory may not drop immediately.
Scaling on memory can be tricky.

---

# ðŸ§  5ï¸âƒ£ Custom Metrics Scaling (Advanced)

Scale based on:

* Request per second
* Queue length
* Kafka lag
* Prometheus metrics

Used in advanced systems.

---

# ðŸ§  6ï¸âƒ£ Scaling Timeline Example

Initial:

3 pods
CPU 40%

Traffic spike:

CPU 85%

HPA triggers:

Scale to 5 pods
Then 7
Then 9

Once traffic drops â†’ scale down gradually.

Autoscaling not instant.
Takes seconds/minutes.

---

# ðŸ§  7ï¸âƒ£ Requests vs Limits Impact on Scaling

If CPU request too high:

Scheduler may not schedule pods.

If limit too low:

Pods get throttled.

Balanced configuration is critical.

Example:

```yaml
resources:
  requests:
    cpu: "250m"
  limits:
    cpu: "1"
```

---

# ðŸ§  8ï¸âƒ£ Cold Start Problem

When scaling up:

* New pods must pull image
* Start JVM
* Initialize DB connections
* Warm cache

If image large â†’ scaling slow.

Optimization needed (Step 5 importance).

---

# ðŸ§  9ï¸âƒ£ Stateless Requirement for Scaling

Only stateless services scale easily.

Stateful apps require:

* Sticky sessions
* Shared storage
* Distributed cache

Backend principle:

Application containers must be stateless.

---

# ðŸ§  ðŸ”Ÿ Capacity Planning Thinking

Senior-level thinking:

If:

1 pod handles 200 RPS
And traffic peak = 2000 RPS

Need:

~10 pods minimum

Add buffer.

Never rely only on autoscaling.

---

# ðŸ§  1ï¸âƒ£1ï¸âƒ£ Scaling Pitfalls

Common mistakes:

âŒ Scaling CPU-bound app without DB scaling
âŒ Scaling app but DB becomes bottleneck
âŒ No connection pool tuning
âŒ Too many pods causing DB overload

Scaling must consider entire system.

---

# ðŸ§  1ï¸âƒ£2ï¸âƒ£ Real Interview Scenarios

---

### Scenario 1

Traffic spike causes high latency.

Possible:

* HPA threshold too high
* Image pull delay
* CPU throttling
* DB bottleneck

---

### Scenario 2

Pods scale to 10 but latency still high.

Likely:

* DB overloaded
* Cache missing
* External API slow

Scaling app layer alone not enough.

---

### Scenario 3

Pods constantly scale up and down.

Called:

â€œScaling thrashingâ€

Solution:

* Adjust HPA thresholds
* Add stabilization window

---

# ðŸ§  1ï¸âƒ£3ï¸âƒ£ Node Scaling

If cluster nodes full:

New pods cannot schedule.

Use:

Cluster Autoscaler.

Scaling layers:

* Pod scaling (HPA)
* Node scaling (Cluster Autoscaler)

---

# ðŸ§  1ï¸âƒ£4ï¸âƒ£ Production Scaling Strategy

âœ” Define minReplicas
âœ” Define maxReplicas
âœ” Monitor CPU & memory
âœ” Pre-warm frequently used services
âœ” Monitor DB load
âœ” Load test before release

---

# ðŸ§  1ï¸âƒ£5ï¸âƒ£ Senior-Level Answer Structure

If asked:

â€œHow do you handle traffic spike?â€

Answer:

* Use HPA for horizontal scaling
* Ensure readiness probe correct
* Keep image small for fast scaling
* Monitor DB and downstream services
* Use caching
* Plan capacity proactively

Clear. Structured. Mature.

---

# ðŸŽ¯ STEP 13 REVISION CHECKLIST

You must confidently explain:

âœ” Vertical vs horizontal scaling
âœ” HPA configuration
âœ” CPU vs memory scaling
âœ” Custom metrics scaling
âœ” Cold start problem
âœ” Stateless requirement
âœ” Capacity planning
âœ” Scaling pitfalls
âœ” Node autoscaling

If you can explain all clearly â†’
Scaling maturity achieved.

---

When ready, type:

**14**

Next file:

ðŸ“ `14-security-hardening-container-cloud.md`
(Container security + image scanning + least privilege + network policies + production hardening)
