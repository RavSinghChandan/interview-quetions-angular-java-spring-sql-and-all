# KUBERNETES â€” LEVEL 5 (ADVANCED)

**Stage Title: â€œYou Become the Engineer Called When Production Clusters Breakâ€**

*(Story continues â€” now you enter real production engineering. This is where Kubernetes stops being theoretical and starts being mission-critical.)*

---

# ðŸŽ¯ OBJECTIVE OF THIS LEVEL

After this level you will be able to:

* debug real production cluster failures
* analyze pod crashes
* diagnose networking issues
* fix scheduling problems
* troubleshoot performance bottlenecks
* investigate node failures

This is where you become:

```
Kubernetes User â†’ Production Troubleshooter
```

---

# 1ï¸âƒ£ REALITY â€” PRODUCTION CLUSTERS FAIL DIFFERENTLY

Real failures rarely say:

> â€œError: Something brokeâ€

Instead they look like:

* pods stuck pending
* service unreachable
* CPU spike
* random restarts
* slow response
* deployment stuck

Advanced engineers donâ€™t guess.

They investigate systematically.

---

# 2ï¸âƒ£ THE GOLDEN DEBUG RULE

When something fails:

Never restart first.

Always inspect first.

Checklist:

```
kubectl get pods
kubectl describe pod
kubectl logs
kubectl get events
```

This solves most issues.

---

# 3ï¸âƒ£ POD STUCK IN PENDING

Check:

```
kubectl describe pod podName
```

Look for:

```
FailedScheduling
```

Common causes:

* insufficient CPU
* insufficient memory
* node selector mismatch
* taints
* no nodes available

Pending = scheduler couldnâ€™t place pod.

---

# 4ï¸âƒ£ POD CRASHING (CRASHLOOPBACKOFF)

Check logs:

```
kubectl logs podName
```

Check previous logs:

```
kubectl logs podName --previous
```

Reasons:

* app crash
* bad config
* missing env variable
* dependency failure

---

# 5ï¸âƒ£ IMAGE PULL ERRORS

Error:

```
ImagePullBackOff
```

Check:

```
kubectl describe pod
```

Common causes:

* wrong image name
* private registry auth missing
* network issue

Fix secret auth:

```
kubectl create secret docker-registry regcred
```

---

# 6ï¸âƒ£ SERVICE NOT REACHABLE

Check service:

```
kubectl get svc
```

Check endpoints:

```
kubectl get endpoints
```

If endpoints empty â†’ service not connected to pods.

Cause:

Label mismatch.

---

# 7ï¸âƒ£ LABEL DEBUGGING

Check pod labels:

```
kubectl get pods --show-labels
```

Check service selector:

```
kubectl describe svc serviceName
```

Labels must match exactly.

---

# 8ï¸âƒ£ POD RESTARTING RANDOMLY

Check restart count:

```
kubectl get pods
```

Check reason:

```
kubectl describe pod
```

Common causes:

* OOM kill
* failing health check
* crashing process

---

# 9ï¸âƒ£ MEMORY CRASH DETECTION

If container killed:

Look for:

```
OOMKilled
```

Fix by increasing limits:

```
resources:
  limits:
    memory: "512Mi"
```

---

# ðŸ”Ÿ NODE FAILURE DEBUGGING

Check nodes:

```
kubectl get nodes
```

If node NotReady:

Describe:

```
kubectl describe node nodeName
```

Check conditions:

```
MemoryPressure
DiskPressure
NetworkUnavailable
```

---

# 11ï¸âƒ£ POD RUNNING BUT APP NOT WORKING

Enter container:

```
kubectl exec -it podName -- bash
```

Test inside:

```
curl localhost:3000
```

If works inside but not outside â†’ networking issue.

---

# 12ï¸âƒ£ NETWORK DEBUG FLOW

Check DNS:

```
kubectl exec podName -- nslookup serviceName
```

Check connectivity:

```
kubectl exec podName -- ping serviceName
```

Check endpoints:

```
kubectl get endpoints
```

---

# 13ï¸âƒ£ DEPLOYMENT STUCK

Check rollout:

```
kubectl rollout status deployment/app
```

Describe deployment:

```
kubectl describe deployment app
```

Common causes:

* readiness probe failing
* image pull error
* resource shortage

---

# 14ï¸âƒ£ READINESS PROBE FAILURES

If readiness fails:

Pod runs but not added to service.

Check probe:

```
kubectl describe pod
```

Fix endpoint path or port.

---

# 15ï¸âƒ£ RESOURCE BOTTLENECK ANALYSIS

Check usage:

```
kubectl top pods
kubectl top nodes
```

High CPU or memory = scaling needed.

---

# 16ï¸âƒ£ CLUSTER EVENTS â€” HIDDEN GOLD

Always check:

```
kubectl get events --sort-by=.metadata.creationTimestamp
```

Events reveal real reason for failures.

---

# 17ï¸âƒ£ STORAGE FAILURES

If pod stuck mounting volume:

Check:

```
kubectl describe pod
```

Common issues:

* PVC not bound
* storage class missing
* disk full

---

# 18ï¸âƒ£ REAL INCIDENT DEBUG FLOW (USED BY SENIORS)

When system fails:

Follow this exact order:

```
Pods â†’ Logs â†’ Events â†’ Nodes â†’ Services â†’ Network â†’ Resources
```

Never random debugging.

Always layered approach.

---

# 19ï¸âƒ£ THE PRODUCTION MINDSET

Beginners restart pods.

Advanced engineers ask:

```
What killed it?
What changed?
What resource exhausted?
What dependency failed?
```

Because Kubernetes failures always have a cause.

---

# 20ï¸âƒ£ ADVANCED COMPLETION CHECK

You can now:

âœ” diagnose pod failures
âœ” debug scheduling issues
âœ” fix service connectivity
âœ” detect memory crashes
âœ” analyze node failures
âœ” troubleshoot deployments
âœ” investigate cluster events
âœ” debug real production systems

---

# FINAL LINE

At this point:

> You donâ€™t fear Kubernetes failures.

Because you know how to investigate them.

That is the difference between:

Engineer â†’ Production Engineer.

---

END OF LEVEL 5 â€” KUBERNETES ADVANCED
