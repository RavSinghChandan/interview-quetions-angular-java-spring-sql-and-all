Good. Now we move to the networking abstraction that makes microservices possible.

---

# ğŸ“ File: `05-service-deep-dive-clusterip-nodeport-loadbalancer.md`

# ğŸ”¥ STEP 5 â€” Service Deep Dive (ClusterIP + NodePort + LoadBalancer + kube-proxy)

This is critical.

Interviewers ask:

* Why do we need Service?
* What happens when pod IP changes?
* How does load balancing work internally?
* What is kube-proxy?
* Difference between ClusterIP, NodePort, LoadBalancer?

You must answer with system clarity.

---

# ğŸ§  1ï¸âƒ£ Why Service Exists

Pods are ephemeral.

If pod crashes â†’ new pod created â†’ new IP.

Example:

Pod IP:

```
10.0.0.15
```

After restart:

```
10.0.0.27
```

If other services depend on pod IP â†’ broken.

Service solves this.

Service provides:

âœ” Stable virtual IP
âœ” DNS name
âœ” Load balancing across pods

---

# ğŸ§  2ï¸âƒ£ Basic Service Example

```yaml
apiVersion: v1
kind: Service
metadata:
  name: user-service
spec:
  selector:
    app: user
  ports:
    - port: 80
      targetPort: 8080
  type: ClusterIP
```

Key fields:

* selector â†’ which pods
* port â†’ service port
* targetPort â†’ container port

---

# ğŸ§  3ï¸âƒ£ How Service Actually Works

Flow:

```
Client â†’ Service â†’ Pod
```

Service selects pods via labels:

```yaml
selector:
  app: user
```

If 3 pods match â†’ traffic distributed across 3.

---

# ğŸ§  4ï¸âƒ£ kube-proxy Role

kube-proxy runs on every node.

It:

* Watches Services
* Configures iptables rules
* Routes traffic to appropriate pods

Load balancing is not magic.
It is iptables rules configured by kube-proxy.

---

# ğŸ§  5ï¸âƒ£ ClusterIP (Default)

Default service type.

Accessible:

Only inside cluster.

Example:

```
http://user-service
```

Resolved via internal DNS.

Use case:

Service-to-service communication.

---

# ğŸ§  6ï¸âƒ£ NodePort

Exposes service on each nodeâ€™s IP.

Example:

```yaml
type: NodePort
```

Kubernetes assigns port like:

```
30007
```

Access via:

```
http://node-ip:30007
```

Use case:

Basic external access.

Not ideal for production internet traffic.

---

# ğŸ§  7ï¸âƒ£ LoadBalancer

Cloud-managed load balancer created.

Example:

```yaml
type: LoadBalancer
```

Cloud provider:

* AWS ELB
* GCP Load Balancer

Public IP assigned.

Best for exposing APIs externally.

---

# ğŸ§  8ï¸âƒ£ Internal DNS Resolution

Inside cluster:

Call service using:

```
http://user-service
```

Full DNS:

```
user-service.default.svc.cluster.local
```

But short name works inside same namespace.

Important interview point.

---

# ğŸ§  9ï¸âƒ£ How Load Balancing Works Internally

If 3 pods exist:

* Pod A
* Pod B
* Pod C

Service distributes traffic roughly equally.

kube-proxy uses round-robin at connection level.

Important:

It is L4 load balancing.

Not advanced traffic splitting.

---

# ğŸ§  ğŸ”Ÿ What Happens If One Pod Fails?

If readiness fails:

* Pod removed from service endpoints
* kube-proxy stops routing traffic to it

Automatic resilience.

---

# ğŸ§  1ï¸âƒ£1ï¸âƒ£ Endpoints Object

Service maintains endpoints list.

Check:

```bash
kubectl get endpoints user-service
```

Shows pod IPs currently serving traffic.

If no endpoints â†’ service unreachable.

---

# ğŸ§  1ï¸âƒ£2ï¸âƒ£ Common Service Misconfiguration

---

### Scenario 1 â€” Service not routing traffic

Possible:

* Label mismatch
* Wrong targetPort
* Pod not ready

---

### Scenario 2 â€” Service accessible internally but not externally

Likely:

* Using ClusterIP instead of LoadBalancer
* Security group blocking traffic

---

### Scenario 3 â€” High latency

Possible:

* Too few replicas
* Network bottleneck
* Cross-node traffic overhead

---

# ğŸ§  1ï¸âƒ£3ï¸âƒ£ Headless Service (Advanced Concept)

Set:

```yaml
clusterIP: None
```

Used for:

* StatefulSets
* Direct pod-to-pod DNS

No load balancing.
DNS returns individual pod IPs.

Senior awareness point.

---

# ğŸ§  1ï¸âƒ£4ï¸âƒ£ Service vs Ingress

Service:

Routes traffic to pods.

Ingress:

Routes HTTP traffic based on:

* Host
* Path

Ingress sits above Service.

Flow:

```
User â†’ Ingress â†’ Service â†’ Pod
```

---

# ğŸ§  1ï¸âƒ£5ï¸âƒ£ Senior-Level Answer Structure

If asked:

â€œHow does service load balance traffic?â€

Answer:

* Service selects pods using labels
* kube-proxy configures iptables rules
* Requests routed to pod IPs
* Readiness probe ensures only healthy pods receive traffic

Clear. Structured. Mature.

---

# ğŸ¯ STEP 5 REVISION CHECKLIST

You must confidently explain:

âœ” Why Service needed
âœ” Stable virtual IP
âœ” Selector mechanism
âœ” kube-proxy role
âœ” ClusterIP vs NodePort vs LoadBalancer
âœ” Endpoints object
âœ” Internal DNS
âœ” Headless service
âœ” Service vs Ingress

If you can explain this clearly â†’
Service-level maturity achieved.

---

When ready, type:

**6**

Next file:

ğŸ“ `06-request-flow-load-balancing-internals.md`
(Full traffic path deep dive â€” User â†’ LB â†’ Ingress â†’ Service â†’ Pod + packet flow explanation + scaling interaction)
