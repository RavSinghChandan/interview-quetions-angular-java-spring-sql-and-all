Excellent.
Now we move into **real cluster intelligence**.

This is where Kubernetes stops being â€œYAMLâ€ and becomes **resource orchestration logic**.

---

# ğŸ“ File: `11-resource-management-scheduling-deep.md`

# ğŸ”¥ STEP 11 â€” Resource Management + Scheduling + QoS + Eviction

(Cluster Intelligence â€” Senior Orchestration Depth)

Interviewers may ask:

* How does scheduler decide node?
* What happens if cluster runs out of memory?
* What is QoS class?
* What is eviction?
* What happens under node pressure?

You must answer with control-plane understanding.

---

# ğŸ§  1ï¸âƒ£ Why Resource Management Is Critical

Cluster has finite resources:

* CPU
* Memory
* Disk

If unmanaged:

* One pod can starve others
* Node crashes
* Cascading failure

Kubernetes enforces resource governance.

---

# ğŸ§  2ï¸âƒ£ Requests vs Limits (Core Concept)

Example:

```yaml
resources:
  requests:
    cpu: "200m"
    memory: "256Mi"
  limits:
    cpu: "500m"
    memory: "512Mi"
```

### Requests

Minimum guaranteed resource.
Used by scheduler.

### Limits

Maximum allowed.
Enforced by kernel.

Very important distinction.

---

# ğŸ§  3ï¸âƒ£ How Scheduler Uses Requests

Scheduler checks:

```
Node available resources â‰¥ Pod requests
```

If node has:

* 2 CPUs free
* Pod requests 0.5 CPU

Pod can schedule.

If no node fits â†’ Pod stays Pending.

Limits are NOT considered for scheduling.

Only requests.

---

# ğŸ§  4ï¸âƒ£ CPU Limit Behavior

If CPU limit exceeded:

Container is throttled.

Linux cgroups enforce CPU quota.

Result:

* Increased latency
* Slower response
* No crash

CPU overuse â‰  kill.

---

# ğŸ§  5ï¸âƒ£ Memory Limit Behavior

If memory limit exceeded:

Kernel OOM killer kills container.

Result:

* OOMKilled event
* Container restarts
* Pod restart count increases

Memory overuse = kill.

Critical difference from CPU.

---

# ğŸ§  6ï¸âƒ£ Quality of Service (QoS) Classes

Kubernetes assigns QoS class based on request/limit.

### Guaranteed

Requests = Limits for all containers.

Example:

```yaml
requests:
  cpu: "500m"
  memory: "512Mi"
limits:
  cpu: "500m"
  memory: "512Mi"
```

Highest priority.

---

### Burstable

Requests < Limits.

Common case.

---

### BestEffort

No requests, no limits.

Lowest priority.

Example:

```yaml
resources: {}
```

Dangerous in production.

---

# ğŸ§  7ï¸âƒ£ Eviction Under Node Pressure

If node memory pressure occurs:

Kubernetes evicts pods in this order:

1. BestEffort
2. Burstable
3. Guaranteed

QoS determines survival.

Senior awareness point.

---

# ğŸ§  8ï¸âƒ£ Node Pressure Conditions

Check node:

```bash
kubectl describe node mynode
```

Conditions:

* MemoryPressure
* DiskPressure
* PIDPressure

If MemoryPressure = True

Eviction may occur.

---

# ğŸ§  9ï¸âƒ£ Pod Priority (Advanced)

Pods can define priority:

```yaml
priorityClassName: high-priority
```

Higher priority pods:

* Scheduled first
* Lower priority pods evicted first

Used in critical systems.

---

# ğŸ§  ğŸ”Ÿ Scheduling Algorithm Overview

Scheduler steps:

1. Filter nodes (feasible nodes)
2. Score nodes
3. Select best node

Filters consider:

* Resource availability
* Node selectors
* Affinity rules
* Taints

Scoring considers:

* Least requested
* Balanced resource allocation
* Custom plugins

Advanced orchestration logic.

---

# ğŸ§  1ï¸âƒ£1ï¸âƒ£ Taints and Tolerations

Taint node:

```bash
kubectl taint nodes node1 key=value:NoSchedule
```

Only pods with matching toleration can schedule.

Used for:

* Dedicated nodes
* Special workloads

---

# ğŸ§  1ï¸âƒ£2ï¸âƒ£ Node Affinity

Example:

```yaml
affinity:
  nodeAffinity:
    requiredDuringSchedulingIgnoredDuringExecution:
      nodeSelectorTerms:
        - matchExpressions:
            - key: zone
              operator: In
              values:
                - us-east-1a
```

Force pod to schedule in specific zone.

Used for data locality.

---

# ğŸ§  1ï¸âƒ£3ï¸âƒ£ Real Failure Scenario

Scenario:

Pods stuck in Pending.

Check:

```bash
kubectl describe pod mypod
```

Likely:

* Insufficient CPU
* Insufficient memory
* Node taint mismatch
* Affinity mismatch

Most common real-world issue.

---

# ğŸ§  1ï¸âƒ£4ï¸âƒ£ Production Best Practices

âœ” Always define requests
âœ” Avoid BestEffort pods
âœ” Tune limits properly
âœ” Monitor node pressure
âœ” Separate workloads by priority
âœ” Consider node autoscaler

---

# ğŸ§  1ï¸âƒ£5ï¸âƒ£ Senior-Level Answer Structure

If asked:

â€œWhat happens if node runs out of memory?â€

Strong answer:

* Node enters MemoryPressure state
* Kubernetes may evict lower QoS pods
* BestEffort evicted first
* Guaranteed pods protected
* Cluster autoscaler may add new node

Clear. Structured. Mature.

---

# ğŸ¯ STEP 11 REVISION CHECKLIST

You must confidently explain:

âœ” Requests vs limits
âœ” Scheduler logic
âœ” CPU throttling vs OOM kill
âœ” QoS classes
âœ” Eviction order
âœ” Node pressure conditions
âœ” Taints & tolerations
âœ” Affinity rules
âœ” Pending pod debugging

If you can explain all clearly â†’
Cluster resource mastery achieved.

---

When ready, type:

**12**

Next file:

ğŸ“ `12-self-healing-node-failure-recovery.md`
(Node failure detection + rescheduling + controller reaction + cluster resilience mechanics deep dive)
